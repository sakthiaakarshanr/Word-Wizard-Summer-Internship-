{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f605c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b550b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      author                    poem_name  TOTAL_WORD_COUNT  \\\n",
      "0  avvaiyaar           அமுதும்‌ அன்பும்‌!                15   \n",
      "1  avvaiyaar                     அழகு எது                18   \n",
      "2  avvaiyaar                       ஆரையடா                15   \n",
      "3  avvaiyaar                  இடம்‌ எங்கே                15   \n",
      "4  avvaiyaar  இன்றுபோல்‌ என்றும்‌ இரும்‌!                15   \n",
      "\n",
      "   UNIQUE_WORD_COUNT  TYPE_TOKEN_RATIO  AVG_WORD_LENGTH  STD_WORD_LENGTH  \\\n",
      "0                 15          1.000000         7.600000         2.184796   \n",
      "1                 16          0.888889         6.166667         2.967416   \n",
      "2                 15          1.000000         7.000000         2.129163   \n",
      "3                 15          1.000000         7.733333         2.694851   \n",
      "4                 15          1.000000         7.800000         2.343786   \n",
      "\n",
      "   HAPAX_LEGOMENA  FUNCTION_WORD_FREQ  STOP_WORD_RATIO  ...  TOTAL_LINES  \\\n",
      "0              15                   0              0.0  ...            4   \n",
      "1              14                   0              0.0  ...            4   \n",
      "2              15                   0              0.0  ...            4   \n",
      "3              15                   0              0.0  ...            4   \n",
      "4              15                   0              0.0  ...            4   \n",
      "\n",
      "   ANAPHORA_SCORE  EPIPHORA_SCORE  ENJAMBMENT_RATIO  ESTIMATED_NOUN_COUNT  \\\n",
      "0             0.0             0.0              0.75                     0   \n",
      "1             0.0             0.0              0.75                     0   \n",
      "2             0.0             0.0              0.75                     0   \n",
      "3             0.0             0.0              0.75                     0   \n",
      "4             0.0             0.0              0.75                     0   \n",
      "\n",
      "   ESTIMATED_VERB_COUNT  NOUN_VERB_RATIO  READABILITY_SCORE  Emotion  \\\n",
      "0                     0              0.0               70.0      Sad   \n",
      "1                     0              0.0               64.0    Happy   \n",
      "2                     0              0.0               70.0      Sad   \n",
      "3                     3              0.0               70.0      Sad   \n",
      "4                     0              0.0               70.0    Happy   \n",
      "\n",
      "   Sentiment  \n",
      "0   Negative  \n",
      "1   Positive  \n",
      "2    Neutral  \n",
      "3   Negative  \n",
      "4   Positive  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\SASTRA\\shanthi mam project\\aif_emo_sen_new.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d944ba96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160 entries, 0 to 159\n",
      "Data columns (total 28 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   author                  160 non-null    object \n",
      " 1   poem_name               160 non-null    object \n",
      " 2   TOTAL_WORD_COUNT        160 non-null    int64  \n",
      " 3   UNIQUE_WORD_COUNT       160 non-null    int64  \n",
      " 4   TYPE_TOKEN_RATIO        160 non-null    float64\n",
      " 5   AVG_WORD_LENGTH         160 non-null    float64\n",
      " 6   STD_WORD_LENGTH         160 non-null    float64\n",
      " 7   HAPAX_LEGOMENA          160 non-null    int64  \n",
      " 8   FUNCTION_WORD_FREQ      160 non-null    int64  \n",
      " 9   STOP_WORD_RATIO         160 non-null    float64\n",
      " 10  CHAR_UNIGRAM_ENTROPY    160 non-null    float64\n",
      " 11  CHAR_BIGRAM_ENTROPY     160 non-null    float64\n",
      " 12  CHAR_TRIGRAM_ENTROPY    160 non-null    float64\n",
      " 13  CHAR_DIVERSITY          160 non-null    int64  \n",
      " 14  RARE_CHAR_RATIO         160 non-null    float64\n",
      " 15  AVG_SYLLABLES_PER_WORD  160 non-null    float64\n",
      " 16  AVG_LINE_LENGTH_WORDS   160 non-null    float64\n",
      " 17  AVG_STANZA_LENGTH       160 non-null    int64  \n",
      " 18  TOTAL_LINES             160 non-null    int64  \n",
      " 19  ANAPHORA_SCORE          160 non-null    float64\n",
      " 20  EPIPHORA_SCORE          160 non-null    float64\n",
      " 21  ENJAMBMENT_RATIO        160 non-null    float64\n",
      " 22  ESTIMATED_NOUN_COUNT    160 non-null    int64  \n",
      " 23  ESTIMATED_VERB_COUNT    160 non-null    int64  \n",
      " 24  NOUN_VERB_RATIO         160 non-null    float64\n",
      " 25  READABILITY_SCORE       160 non-null    float64\n",
      " 26  Emotion                 160 non-null    object \n",
      " 27  Sentiment               160 non-null    object \n",
      "dtypes: float64(15), int64(9), object(4)\n",
      "memory usage: 35.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "358159c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"poem_name\", \"author\",\"Emotion\"], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d9ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TOTAL_WORD_COUNT', 'UNIQUE_WORD_COUNT', 'TYPE_TOKEN_RATIO',\n",
      "       'AVG_WORD_LENGTH', 'STD_WORD_LENGTH', 'HAPAX_LEGOMENA',\n",
      "       'FUNCTION_WORD_FREQ', 'STOP_WORD_RATIO', 'CHAR_UNIGRAM_ENTROPY',\n",
      "       'CHAR_BIGRAM_ENTROPY', 'CHAR_TRIGRAM_ENTROPY', 'CHAR_DIVERSITY',\n",
      "       'RARE_CHAR_RATIO', 'AVG_SYLLABLES_PER_WORD', 'AVG_LINE_LENGTH_WORDS',\n",
      "       'AVG_STANZA_LENGTH', 'TOTAL_LINES', 'ANAPHORA_SCORE', 'EPIPHORA_SCORE',\n",
      "       'ENJAMBMENT_RATIO', 'ESTIMATED_NOUN_COUNT', 'ESTIMATED_VERB_COUNT',\n",
      "       'NOUN_VERB_RATIO', 'READABILITY_SCORE'],\n",
      "      dtype='object')\n",
      "(160, 24)\n",
      "(160,)\n",
      "Train Accuracy: 0.9141\n",
      "Test Accuracy: 0.8750\n",
      "F1-score: 0.5873\n",
      "Confusion Matrix:\n",
      " [[ 9  0  2]\n",
      " [ 0  0  1]\n",
      " [ 1  0 19]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.90      0.82      0.86        11\n",
      "     Neutral       0.00      0.00      0.00         1\n",
      "    Positive       0.86      0.95      0.90        20\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.59      0.59      0.59        32\n",
      "weighted avg       0.85      0.88      0.86        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kisho\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\kisho\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\kisho\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'n_esti = [1000, 2000, 3000, 4000, 5000]\\nmax_depths = [4, 5, 6, 7, 8, 9, 10, 20, 30, None]\\ncrit = [\\'gini\\', \\'entropy\\', \\'log_loss\\']\\ntest_size=[0.2,0.23,0.25,0.28,0.3,0.33,0.35,0.38,0.4]\\n\\nfor i in n_esti:\\n    for j in max_depths:\\n        for k in crit:\\n            for l in range(1,101):\\n                for m in test_size:\\n                    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=m, random_state=l)\\n                    model = RandomForestClassifier(\\n                    n_estimators=i,\\n                    criterion=k,\\n                    n_jobs=-1,\\n                    max_depth=j,\\n                    random_state=42\\n                    )\\n\\n                    model.fit(x_train, y_train)\\n                    y_train_pred = model.predict(x_train)\\n                    y_test_pred = model.predict(x_test)\\n                    train_acc = accuracy_score(y_train, y_train_pred)\\n                    test_acc = accuracy_score(y_test, y_test_pred)\\n                    print(f\"Criterion: {k}, n_estimators: {i}, Max Depth: {j}, Random State: {l}, Test Size: {m}, Test Accuracy: {test_acc:.4f}\")'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "import pickle\n",
    "import cloudpickle\n",
    "\n",
    "# Load the dataset\n",
    "#df = pd.read_csv(r\"C:\\SASTRA\\shanthi mam project\\aif_emo_sen_new.csv\")\n",
    "#print(df.info())\n",
    "#print(df.head())\n",
    "\n",
    "#Encode the target column\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"Sentiment\"])\n",
    "\n",
    "#Features and target\n",
    "x = df.drop(columns = [\"Sentiment\"], axis=1)\n",
    "print(x.columns)\n",
    "\n",
    "#Feature scaling\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "#Train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=57)\n",
    "\n",
    "#Random Forest Classifier\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    criterion='gini',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    max_depth=4\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Prediction\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "class_report = classification_report(y_test,y_test_pred, target_names=le.classes_)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "\"\"\"n_esti = [1000, 2000, 3000, 4000, 5000]\n",
    "max_depths = [4, 5, 6, 7, 8, 9, 10, 20, 30, None]\n",
    "crit = ['gini', 'entropy', 'log_loss']\n",
    "test_size=[0.2,0.23,0.25,0.28,0.3,0.33,0.35,0.38,0.4]\n",
    "\n",
    "for i in n_esti:\n",
    "    for j in max_depths:\n",
    "        for k in crit:\n",
    "            for l in range(1,101):\n",
    "                for m in test_size:\n",
    "                    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=m, random_state=l)\n",
    "                    model = RandomForestClassifier(\n",
    "                    n_estimators=i,\n",
    "                    criterion=k,\n",
    "                    n_jobs=-1,\n",
    "                    max_depth=j,\n",
    "                    random_state=42\n",
    "                    )\n",
    "            \n",
    "                    model.fit(x_train, y_train)\n",
    "                    y_train_pred = model.predict(x_train)\n",
    "                    y_test_pred = model.predict(x_test)\n",
    "                    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "                    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "                    print(f\"Criterion: {k}, n_estimators: {i}, Max Depth: {j}, Random State: {l}, Test Size: {m}, Test Accuracy: {test_acc:.4f}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a951283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, r'C:\\SASTRA\\shanthi mam project\\new_sentiment\\jl\\sent_rf_model.joblib')\n",
    "joblib.dump(scaler, r'C:\\SASTRA\\shanthi mam project\\new_sentiment\\jl\\sent_rf_scaler.joblib')\n",
    "joblib.dump(le, r'C:\\SASTRA\\shanthi mam project\\new_sentiment\\jl\\sent_rf_le.joblib')\n",
    "\n",
    "\n",
    "with open(r'C:\\SASTRA\\shanthi mam project\\new_sentiment\\pic\\sent_rf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(r'C:\\SASTRA\\shanthi mam project\\new_sentiment\\pic\\sent_rf_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open(r'C:\\SASTRA\\shanthi mam project\\new_sentiment\\pic\\sent_rf_le.pkl', 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "\n",
    "with open(r'C:\\SASTRA\\shanthi mam project\\new_sentiment\\clo_pic\\sent_rf_model.cpkl', 'wb') as f:\n",
    "    cloudpickle.dump(model, f)\n",
    "with open(r'C:\\SASTRA\\shanthi mam project\\new_sentiment\\clo_pic\\sent_rf_scaler.cpkl', 'wb') as f:\n",
    "    cloudpickle.dump(scaler, f)\n",
    "with open(r'C:\\SASTRA\\shanthi mam project\\new_sentiment\\clo_pic\\sent_rf_le.cpkl', 'wb') as f:\n",
    "    cloudpickle.dump(le, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
